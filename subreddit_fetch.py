# -*- coding: utf-8 -*-
"""Subreddit_Fetch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjlFcYoz36khC5LKJHHYyWfSW5oeQ3am
"""

from google.colab import drive
drive.mount('/content/drive')

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import pickle
from langchain_groq import ChatGroq
from google.colab import userdata

# !pip install faiss-cpu sentence_transformers langchain groq

# Load the SentenceTransformer for encoding user query
model = SentenceTransformer('all-MiniLM-L6-v2')

# Load FAISS index and mappings (assuming this has been saved previously)
index = faiss.read_index("/content/drive/MyDrive/Data/RedditData/enriched_subreddit_faiss_index.bin")
id_to_subreddit = pickle.load(open('/content/drive/MyDrive/Data/RedditData/id_to_subreddit.pkl', 'rb'))
subreddit_id_to_details = pickle.load(open('/content/drive/MyDrive/Data/RedditData/subreddit_id_to_details.pkl', 'rb'))

# Function to retrieve the most relevant subreddits from FAISS based on user query
def retrieve_similar_subreddits(user_query, top_k=5):
    # Encode the user query into an embedding
    query_embedding = model.encode(user_query).astype('float32')

    # Search for top_k closest embeddings in the FAISS index
    distances, indices = index.search(np.array([query_embedding]), top_k)

    # Retrieve subreddit details from the index
    subreddit_ids = [id_to_subreddit[idx] for idx in indices[0]]
    retrieved_subreddits = [subreddit_id_to_details[subreddit_id] for subreddit_id in subreddit_ids]

    return retrieved_subreddits, distances

# Function to print subreddits in a readable format
def print_retrieved_subreddits(retrieved_subreddits):
    print("Retrieved Subreddits:\n")
    for idx, subreddit in enumerate(retrieved_subreddits, 1):
        print(f"Subreddit #{idx}")
        print(f"  Name: {subreddit['name']}")
        print(f"  Description: {subreddit['description']}")
        print(f"  Subscribers: {subreddit.get('subscribers', 'N/A')}")
        print(f"  Category: {subreddit.get('category', 'N/A')}")
        print(f"  Created Date: {subreddit.get('created_utc', 'N/A')}")
        print("-" * 50)  # Line separator between subreddits

# Example usage
user_query = "Porn"
retrieved_subreddits, distances = retrieve_similar_subreddits(user_query)

# Print the subreddits in a formatted way
print_retrieved_subreddits(retrieved_subreddits)

import os

os.environ["GROQ_API_KEY"] = "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"

llm = ChatGroq(model_name="llama3-70b-8192", temperature=0)

from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Initialize the LangChainGroq model for LLaMA 3
# llm = ChatGroq(model_name="llama3-70b", temperature=0)

# Define a prompt template to generate recommendations based on user interest and retrieved subreddits
prompt_template = """
You are a helpful assistant that recommends Reddit subreddits based on user interests.

User's interest: {user_query}

Available subreddits:
{context}

Based on the user's interest, suggest the most relevant subreddits and explain why they are a good fit.
"""

# Initialize the prompt template
prompt = PromptTemplate(
    template=prompt_template,
    input_variables=["user_query", "context"]
)

def hybrid_search(user_query, top_k=5, faiss_weight=0.7, es_weight=0.3):
    """
    Perform a hybrid search using both FAISS and Elasticsearch
    :param user_query: The query string provided by the user
    :param top_k: Number of top results to return
    :param faiss_weight: Weight assigned to FAISS semantic search
    :param es_weight: Weight assigned to Elasticsearch text search
    :return: A combined list of relevant subreddits
    """
    # Step 1: Retrieve subreddits from FAISS
    retrieved_subreddits_faiss, distances = retrieve_similar_subreddits(user_query, top_k)

    # Step 2: Retrieve subreddits from Elasticsearch
    retrieved_subreddits_elasticsearch = search_subreddits_elasticsearch(user_query, top_k)

    # Step 3: Combine and rank results based on FAISS and Elasticsearch scores
    combined_results = {}

    # Step 3a: Process FAISS results (with distances)
    for i, subreddit in enumerate(retrieved_subreddits_faiss):
        combined_results[subreddit['name']] = {
            'subreddit': subreddit,
            'score': faiss_weight / (1 + distances[0][i])  # FAISS results, lower distance = better match
        }

    # Step 3b: Process Elasticsearch results
    for subreddit in retrieved_subreddits_elasticsearch:
        if subreddit['name'] in combined_results:
            combined_results[subreddit['name']]['score'] += es_weight  # Boost the score if already retrieved via FAISS
        else:
            combined_results[subreddit['name']] = {
                'subreddit': subreddit,
                'score': es_weight  # Elasticsearch result
            }

    # Step 4: Sort by score and return the top results
    sorted_results = sorted(combined_results.values(), key=lambda x: x['score'], reverse=True)

    return [result['subreddit'] for result in sorted_results]

# Example usage of hybrid search
user_query = "communities for learning data science"
results = hybrid_search(user_query, top_k=5)

# Print the hybrid search results
print_retrieved_subreddits(results)

# Function to build context for LangChainGroq prompt
def build_context_from_subreddits(retrieved_subreddits):
    # Format the retrieved subreddits into a context string
    context = "\n".join([f"{i+1}. {subreddit['name']}: {subreddit['description']}" for i, subreddit in enumerate(retrieved_subreddits)])
    return context

# Function to perform hybrid search and use LangChainGroq to generate a response
def hybrid_search_with_groq(user_query, top_k=5):
    # Step 1: Perform hybrid search (FAISS + Elasticsearch)
    retrieved_subreddits_faiss, distances = retrieve_similar_subreddits(user_query, top_k)
    # retrieved_subreddits = hybrid_search(user_query, top_k)

    # Step 2: Build context for the LangChainGroq prompt
    context = build_context_from_subreddits(retrieved_subreddits_faiss)

    # Step 3: Generate the response using LangChainGroq
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    response = llm_chain.run({
        "user_query": user_query,
        "context": context
    })

    return response

# Example usage
user_query = "CS Major"
response = hybrid_search_with_groq(user_query)

# Output the response
print(response)



# pip install groq

